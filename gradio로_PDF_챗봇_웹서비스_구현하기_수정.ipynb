{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RRYSu48huSUW"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Y2eS0lajFgif"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "18z1WwNqvT7X"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gQNNa5dSFPb2",
        "outputId": "b107a395-5a51-4dd2-d239-bc8556cbe692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymupdf==1.22.5 in /usr/local/lib/python3.10/dist-packages (1.22.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf==1.22.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OamsjqdXFK-s"
      },
      "outputs": [],
      "source": [
        "!pip install fitz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfQYmMe1Fbcn"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyxac7klNQdR"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaXNzxE2Dwmf"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download ko_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UcQKUId3X2M"
      },
      "source": [
        "## Load documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k2NZq4h4DKBV"
      },
      "outputs": [],
      "source": [
        "# langchain 라이브러리에서 필요한 모듈들을 가져옵니다.\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from collections import Counter\n",
        "from langchain.document_loaders import PyMuPDFLoader  # PDF 파일을 읽어오는 데 사용\n",
        "from langchain.embeddings import OpenAIEmbeddings  # OpenAI의 임베딩 기능을 사용\n",
        "from langchain.text_splitter import SpacyTextSplitter  # 텍스트를 적절한 크기로 나누기\n",
        "from langchain.vectorstores import Chroma  # 벡터 데이터를 저장하고 검색하는 데 사용\n",
        "\n",
        "# PDF 파일을 읽기 위한 로더를 초기화합니다.\n",
        "loader = PyMuPDFLoader(\"/content/test_sample.pdf\")\n",
        "documents = loader.load()  # 파일을 읽어 문서 데이터를 가져옵니다.\n",
        "\n",
        "# 문서를 처리하기 좋은 크기의 조각으로 나누는 스플리터를 설정합니다.\n",
        "# 'ko_core_news_sm'은 한국어 처리를 위한 Spacy 모델입니다.\n",
        "text_splitter = SpacyTextSplitter(\n",
        "    chunk_size=300,\n",
        "    pipeline=\"ko_core_news_sm\"\n",
        ")\n",
        "splitted_documents = text_splitter.split_documents(documents)  # 문서를 나눕니다.\n",
        "\n",
        "# OpenAI의 임베딩 모델을 초기화합니다. 여기서는 'text-embedding-ada-002' 모델을 사용합니다.\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    openai_api_key=\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wDmeKQV9KlOp"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma(\n",
        "    persist_directory=\"./.data\",  # 데이터 저장 경로 지정\n",
        "    embedding_function=embeddings  # 임베딩 함수 지정\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siLXR-XT0JoI"
      },
      "source": [
        "## Make a retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6ObunFU30Lxh"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYA-H59u0Skn",
        "outputId": "663284c9-ae28-416b-eca7-ee1da707bb66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문서 수: 0\n"
          ]
        }
      ],
      "source": [
        "documents = retriever.get_relevant_documents(\"현충일 제정일은?\")\n",
        "print(f\"문서 수: {len(documents)}\") # 문서 개수 표시\n",
        "\n",
        "for document in documents:\n",
        "    print(f\"문서 내용: {document.page_content}\") # 문서 내용을 표시\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3mZszDFW5aw"
      },
      "source": [
        "### 결과를 k개 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jVWgPJXs1yRq"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "58fAAOHfVLeM"
      },
      "outputs": [],
      "source": [
        "documents = retriever.get_relevant_documents(\"현충일에 대해서 설명해줘!?\")\n",
        "\n",
        "for document in documents:\n",
        "    print(f\"문서 내용: {document.page_content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ia-4OXa5IeP"
      },
      "source": [
        "## Make a chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGx8XblM4shW"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0,\n",
        "                   openai_api_key=\"\"),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjyrGZyeW_iO"
      },
      "source": [
        "## Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YJIbk8hRPN2"
      },
      "outputs": [],
      "source": [
        "input_text = \"문재인 대통령의 취임일은?\"\n",
        "chatbot_response = qa_chain(input_text)\n",
        "print(chatbot_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-jz6zAI5PlW"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UozRGHap6b3A"
      },
      "source": [
        "To create a public link, set `share=True` in `launch()`.  \n",
        "Running on https://localhost:7860/  \n",
        "\n",
        "라는 식의 문구가 나오면 위의 localhost로 시작하는 주소를 클릭하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWXwk0Ms56_t"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# 인터페이스를 생성하고 관리하는 블록 구조를 사용\n",
        "with gr.Blocks() as demo:\n",
        "    # Chatbot: 그라디오의 챗봇 컴포넌트를 생성하여 인터페이스에 추가\n",
        "    chatbot = gr.Chatbot(label=\"PDF 검색챗봇\")  # 챗봇 상단에 \"PDDF검색챗봇\" 레이블이 표시됨\n",
        "    # Textbox: 사용자의 질문을 입력할 수 있는 텍스트 상자를 생성하여 추가\n",
        "    msg = gr.Textbox(label=\"질문 해주세요!\")  # 하단의 채팅창에 \"질문 해주세요!\" 레이블이 표시됨\n",
        "    # Button: 대화를 초기화할 수 있는 버튼을 생성\n",
        "    clear = gr.Button(\"대화를 초기화합니다\")  # \"대화를 초기화합니다\" 레이블의 버튼이 표시됨\n",
        "\n",
        "    # respond 함수: 사용자의 메시지를 받아 챗봇의 응답을 반환하는 함수\n",
        "    def respond(message, chat_history):\n",
        "        # qa_chain 함수: 입력된 질문을 기반으로 답변을 생성 (이 부분은 실제 구현에 따라 다름)\n",
        "        result = qa_chain(message)\n",
        "        bot_message = result['result']  # 챗봇의 답변을 가져옴\n",
        "        bot_message += ' # sources :'  # 답변 출처를 추가하기 위한 태그\n",
        "\n",
        "        # 각 출처 문서를 참조하여 답변에 출처 정보 추가\n",
        "        for i, doc in enumerate(result['source_documents']):\n",
        "            bot_message += '[' + str(i+1) + '] ' + doc.metadata['source'] + ' '\n",
        "\n",
        "        # 사용자의 질문과 챗봇의 답변을 채팅 기록에 추가\n",
        "        chat_history.append((message, bot_message))\n",
        "        # 새 메시지를 입력할 수 있도록 입력 상자를 비우고, 업데이트된 채팅 기록 반환\n",
        "        return \"\", chat_history\n",
        "\n",
        "    # 사용자가 텍스트 상자에 입력한 메시지를 제출하면 respond 함수가 호출\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "    # '초기화' 버튼을 클릭하면 채팅 기록을 초기화\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "# 인터페이스 실행: 웹 인터페이스를 브라우저에서 실행 가능\n",
        "demo.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
